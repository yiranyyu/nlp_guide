nohup: ignoring input

Unknown vocab size: 42399
Total words in training file: 1001247
Total bytes in training file: 6213810
Vocab size: 15669
Initializing unigram table
Filling unigram table
End filling unigram talbe
Begin training
[1 epoch] of process 0, Alpha: 0.025000
[1 epoch] of process 1, Alpha: 0.025000
[1 epoch] of process 2, Alpha: 0.025000
[1 epoch] of process 3, Alpha: 0.025000
[1 epoch] of process 4, Alpha: 0.025000
[1 epoch] of process 5, Alpha: 0.025000
[1 epoch] of process 6, Alpha: 0.025000
[1 epoch] of process 7, Alpha: 0.025000
[2 epoch] of process 1, Alpha: 0.002528
[2 epoch] of process 7, Alpha: 0.001779
[2 epoch] of process 2, Alpha: 0.002778
[2 epoch] of process 5, Alpha: 0.002278
[2 epoch] of process 3, Alpha: 0.001030
[2 epoch] of process 6, Alpha: 0.001529
[2 epoch] of process 4, Alpha: 0.002029
[2 epoch] of process 0, Alpha: 0.000003
[3 epoch] of process 1, Alpha: 0.000003
[3 epoch] of process 7, Alpha: 0.000003
[3 epoch] of process 2, Alpha: 0.000003
[3 epoch] of process 6, Alpha: 0.000003
[3 epoch] of process 5, Alpha: 0.000003
[3 epoch] of process 3, Alpha: 0.000003
[3 epoch] of process 4, Alpha: 0.000003
[3 epoch] of process 0, Alpha: 0.000003
[4 epoch] of process 1, Alpha: 0.000003
[4 epoch] of process 7, Alpha: 0.000003
[4 epoch] of process 2, Alpha: 0.000003
[4 epoch] of process 6, Alpha: 0.000003
[4 epoch] of process 5, Alpha: 0.000003
[4 epoch] of process 3, Alpha: 0.000003
[4 epoch] of process 4, Alpha: 0.000003
[4 epoch] of process 0, Alpha: 0.000003
[5 epoch] of process 1, Alpha: 0.000003
[5 epoch] of process 7, Alpha: 0.000003
[5 epoch] of process 2, Alpha: 0.000003
[5 epoch] of process 6, Alpha: 0.000003
[5 epoch] of process 5, Alpha: 0.000003
[5 epoch] of process 3, Alpha: 0.000003
[5 epoch] of process 4, Alpha: 0.000003
[5 epoch] of process 0, Alpha: 0.000003

Completed training. Training took 6.825757058461507 minutes
Saving model to ./model/1m_words.txt_5_skip-gram_neg5.model
data path: /root/nlp/thunlp_guide/data/word2vec/1m_words.txt
save path: /root/nlp/thunlp_guide/model/1m_words.txt_5_skip-gram_neg5.model
